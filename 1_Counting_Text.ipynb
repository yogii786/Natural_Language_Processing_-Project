{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbKXvvUhhMn4"
   },
   "source": [
    "# NLTK and the Basics - Counting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "colab_type": "code",
    "id": "gpLnasOChMoU",
    "outputId": "800635a1-980b-4b56-e30c-b9e7476819c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> l\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: q\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> q\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download()\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')  # Project/module // gutenberg = consist of collection of text files\n",
    "#nltk.corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0JVeJT3hMrN"
   },
   "source": [
    "NLTK comes with pre-packed text data. \n",
    "\n",
    "Project Gutenberg is a group that digitizes books and literature that are mostly in the pubic domain.  These works make great examples for practicing NLP.  If you interested in Project Gutenberg, I recommend checking out their site. http://www.gutenberg.org/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "18LCFk78hMrm",
    "outputId": "2bb53edd-71bd-4011-93ae-1c6bb1a3c4ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()   #  , nltk = tools -> corpus =corpus = collection of document -> gutenberg -. project (collection of files) -> files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yG3QJaFnhMte"
   },
   "source": [
    "You will notice that every file name has the letter \"u\" before it. The 'u' is part of the external representation of the file name, meaning it's a Unicode string as opposed to a byte string. It is not part of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ29dU_8hMt4"
   },
   "outputs": [],
   "source": [
    "md = nltk.corpus.gutenberg.words(\"chesterton-thursday.txt\")  # md = variable ,Ascii , binary  ,u = unicode \\u , A - 1 , b_ 0, 0000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "EZt035tle6F2",
    "outputId": "e845c6ce-2774-4df1-bc28-8909910fbf88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Man', 'Who', 'Was', 'Thursday', 'by', ...]\n"
     ]
    }
   ],
   "source": [
    "print(md)   # content of my file ,, # .....  = lot of words are there so it is showing only few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UAgwS_lIhMvY",
    "outputId": "231ef54a-922b-444b-aae9-27f5ec390f3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'The',\n",
       " 'Man',\n",
       " 'Who',\n",
       " 'Was',\n",
       " 'Thursday',\n",
       " 'by',\n",
       " 'G',\n",
       " '.',\n",
       " 'K',\n",
       " '.',\n",
       " 'Chesterton',\n",
       " '1908',\n",
       " ']',\n",
       " 'To',\n",
       " 'Edmund',\n",
       " 'Clerihew',\n",
       " 'Bentley',\n",
       " 'A',\n",
       " 'cloud',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mind',\n",
       " 'of',\n",
       " 'men',\n",
       " ',',\n",
       " 'and',\n",
       " 'wailing',\n",
       " 'went',\n",
       " 'the',\n",
       " 'weather',\n",
       " ',',\n",
       " 'Yea',\n",
       " ',',\n",
       " 'a',\n",
       " 'sick',\n",
       " 'cloud',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'soul',\n",
       " 'when',\n",
       " 'we',\n",
       " 'were',\n",
       " 'boys',\n",
       " 'together',\n",
       " '.',\n",
       " 'Science',\n",
       " 'announced',\n",
       " 'nonentity',\n",
       " 'and',\n",
       " 'art',\n",
       " 'admired',\n",
       " 'decay',\n",
       " ';',\n",
       " 'The',\n",
       " 'world',\n",
       " 'was',\n",
       " 'old',\n",
       " 'and',\n",
       " 'ended',\n",
       " ':',\n",
       " 'but',\n",
       " 'you',\n",
       " 'and',\n",
       " 'I',\n",
       " 'were',\n",
       " 'gay',\n",
       " ';',\n",
       " 'Round',\n",
       " 'us',\n",
       " 'in',\n",
       " 'antic',\n",
       " 'order',\n",
       " 'their',\n",
       " 'crippled',\n",
       " 'vices',\n",
       " 'came',\n",
       " '--',\n",
       " 'Lust',\n",
       " 'that',\n",
       " 'had',\n",
       " 'lost',\n",
       " 'its',\n",
       " 'laughter',\n",
       " ',',\n",
       " 'fear',\n",
       " 'that',\n",
       " 'had',\n",
       " 'lost',\n",
       " 'its',\n",
       " 'shame',\n",
       " '.',\n",
       " 'Like',\n",
       " 'the',\n",
       " 'white',\n",
       " 'lock',\n",
       " 'of',\n",
       " 'Whistler',\n",
       " ',']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md[0:100]  # index 0 to 99 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzajKfDXhMw7"
   },
   "source": [
    "We can count how many times a word appears in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "rSUDVxxKhMxM",
    "outputId": "17196933-0ba4-4cd9-af2b-b5fcdda93d54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.count(\"boys\")  # counting the word in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "gz6hZ7JnhMyp",
    "outputId": "3797b0ff-c26d-4a63-dcb8-36d5646e60a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.count(\"boat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ZJCuyR0EhMz7",
    "outputId": "31580562-d1a2-4017-f650-c8e5a4cab1ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.count(\"Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "S-k0qN5jhM1H",
    "outputId": "ee12eca8-a630-4b63-ce04-bc43e04bf590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.count(\"laptop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmDS6mXJhM2V"
   },
   "source": [
    "We can get an idea of how long the book is by seeing how many items are in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "mg5o5b93hM2l",
    "outputId": "4b1517ad-b4b2-40eb-ee25-9cdcaef07c3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69213"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md)  # count the number of words in file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14hlxJGyhM3v"
   },
   "source": [
    "We can see how many unique words are used in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGxTIdpghM3_"
   },
   "outputs": [],
   "source": [
    "md_set = set(md) # finding unique words inset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "ATCzgv29hM5H",
    "outputId": "99ed4acd-c3c1-4a1b-a4be-b805d5f90042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md_set)  # count unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1myKEhmmhM6Q"
   },
   "source": [
    "We can calculate the average number of times any given word is used in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vF9YPPWhM6g"
   },
   "outputs": [],
   "source": [
    "from __future__ import division #we import this since we are using Python 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "lbRpeipUhM7j",
    "outputId": "2cebcc44-5548-4682-8581-ea5e2cb6543b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.167915381225209"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md)/len(md_set)   # specific words average appearing 10 time in my file , cal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oa5Kvn61hM8j"
   },
   "source": [
    "We can look at the book as a lists of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfmxxKjdhM8z"
   },
   "outputs": [],
   "source": [
    "md_sents = nltk.corpus.gutenberg.sents(\"melville-moby_dick.txt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aec5h9I3hM9u"
   },
   "source": [
    "We can calculate the average number of words per sentence in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "IPZuZbBdhM94",
    "outputId": "2b21e1e1-2316-4e8b-db84-becd8135fb8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.880703847300924"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md)/len(md_sents)  , md_sents = collection of unique sentences  , t"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Counting Text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
